{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b739d60",
   "metadata": {},
   "source": [
    "# Bach Figured bass analysis\n",
    "\n",
    "## Done\n",
    "- Got a countvectorized representation\n",
    "\n",
    "## TO DO:\n",
    "- The countvectorized_data includes only n-grams of figuration. Next, combine figuration and bass movement counted in half-step (e.g. +2, -1, etc...)\n",
    "    - When I create the string I can a word in between figure bass to describe the bass motion. Then I would copute the n-grams only for odd numbers. e.g. RO would be: !6! [+2] !6 5!\n",
    "    - the ! are rather ugly, better use [] and {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56f2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e72f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_and_clean(filename):\n",
    "    part_types = pd.read_csv(filename, \n",
    "                     skiprows=3, sep='\\t',nrows=0)\n",
    "    df = pd.read_csv(filename, \n",
    "                     skiprows=13, names=['fb'],\n",
    "                     sep='\\t', usecols = np.argwhere(part_types.columns=='**fb').flatten(),\n",
    "                     )\n",
    "    # Drop rows corresponding to bar number or where the harmony doesn't change\n",
    "    df.drop(index=np.argwhere(df.loc[:,'fb'].str.contains('=').values).flatten(),inplace=True)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    df.drop(index=df.index[-2:], inplace=True)\n",
    "    df.drop(index=np.argwhere(df.loc[:,'fb'].str.contains('\\\\.').values).flatten(),inplace=True)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "#     df.head()\n",
    "    \n",
    "#     df['fb'] = [f'*{s}*' for s in df['fb']]\n",
    "    # convert to a string\n",
    "    A = list(df['fb'].values)\n",
    "    string = ''\n",
    "    for i, s in enumerate(A):\n",
    "        if i>0:\n",
    "            string += ' '\n",
    "        string += f\"[{s}]\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16dd4b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BWV_13.06_</th>\n",
       "      <td>[6] [6] [6] [6 5] [6] [7] [nr6] [5] [5_] [5] [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_174.05_</th>\n",
       "      <td>[5] [6] [6] [5] [6 5] [4] [3] [9] [6] [5] [#6\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_251_</th>\n",
       "      <td>[6] [6] [7] [5] [6] [nr6] [6 nr5] [4] [3] [6] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_244.32_</th>\n",
       "      <td>[5] [6] [5] [6] [6] [4] [3] [6 4 2] [6 4 2] [6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_248.42_</th>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            fb\n",
       "BWV_13.06_   [6] [6] [6] [6 5] [6] [7] [nr6] [5] [5_] [5] [...\n",
       "BWV_174.05_  [5] [6] [6] [5] [6 5] [4] [3] [9] [6] [5] [#6\\...\n",
       "BWV_251_     [6] [6] [7] [5] [6] [nr6] [6 nr5] [4] [3] [6] ...\n",
       "BWV_244.32_  [5] [6] [5] [6] [6] [4] [3] [6 4 2] [6 4 2] [6...\n",
       "BWV_248.42_                                                [6]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basefolder = \"../Data/Music/Figured_bass/Bach_chorale_FB-master/FB_source/translated_kern/\"\n",
    "string_dict = {}\n",
    "for file in listdir(basefolder):\n",
    "    if file[-4:] == '.krn':\n",
    "        string_dict[file[:-15]] = import_and_clean(basefolder + file)\n",
    "\n",
    "df = pd.DataFrame.from_dict(string_dict,orient='index',columns=['fb'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6681f",
   "metadata": {},
   "source": [
    "# TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6ec5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ ]', '[# 7]', '[#2\\\\]', '[#2| 4]', '[#2|]', '[#4| 2]', '[#4| 6]', '[#4|]', '[#5\\\\ #]', '[#5\\\\ 4]', '[#5\\\\]', '[#5| #]', '[#5| 4 9]', '[#5| 4]', '[#5| 9 3]', '[#5|]', '[#6\\\\ #4| 2]', '[#6\\\\ #4| 3]', '[#6\\\\ -r5]', '[#6\\\\ 4 3]', '[#6\\\\ 4]', '[#6\\\\ 5]', '[#6\\\\ n]', '[#6\\\\ nr5]', '[#6\\\\]', '[#7\\\\ 2]', '[#7\\\\ 4 2]', '[#7\\\\ 4]', '[#7\\\\ 5]', '[#7\\\\]', '[#7| 5 4]', '[#7| 7]', '[#7|]', '[#]', '[#_]', '[#r5]', '[#r6 #4| 2]', '[#r6 5]', '[#r7]', '[*]', '[-]', '[-r4]', '[-r5]', '[-r6 4 -r2]', '[-r6 4 2]', '[-r6 4]', '[-r6]', '[-r7 3]', '[-r7 5]', '[-r7]', '[2 #4| 6]', '[2 -5/]', '[2 4]', '[2 nr4 6]', '[2]', '[3 5 7]', '[3 5]', '[3 6 #4|]', '[3 6]', '[3 7]', '[3 8]', '[3]', '[4 #2\\\\]', '[4 #2|]', '[4 #5| 9]', '[4 #7| 5]', '[4 2 5]', '[4 2]', '[4 5 2]', '[4 5]', '[4 6 2]', '[4 6 8]', '[4 6]', '[4 7]', '[4 9 #7\\\\]', '[4 9]', '[4]', '[5 #2|]', '[5 #6\\\\]', '[5 #]', '[5 -]', '[5 -r4 2]', '[5 2]', '[5 3 7]', '[5 3]', '[5 4 #2|]', '[5 4 -r2]', '[5 4 2]', '[5 4]', '[5 6]', '[5 7]', '[5 8]', '[5 ]', '[5 n]', '[5]', '[5_ 3_]', '[5_]', '[6 #4| #2\\\\]', '[6 #4| 2]', '[6 #4| 3]', '[6 #4| 5]', '[6 #4|]', '[6 #]', '[6 -]', '[6 -r5]', '[6 3]', '[6 4 #2\\\\]', '[6 4 #2|]', '[6 4 -]', '[6 4 2]', '[6 4 3]', '[6 4 9]', '[6 4 nr3]', '[6 4]', '[6 5 #]', '[6 5 -]', '[6 5 3]', '[6 5 n]', '[6 5]', '[6 8 -]', '[6 8]', '[6 n]', '[6 nr4 2]', '[6 nr4]', '[6 nr5]', '[6]', '[6_]', '[7 #2|]', '[7 #5\\\\ 2]', '[7 #5\\\\ 3]', '[7 #5\\\\]', '[7 #5| 2]', '[7 #5|]', '[7 #]', '[7 -]', '[7 -r5]', '[7 2 4]', '[7 2]', '[7 3]', '[7 4 -r2]', '[7 4 2]', '[7 4]', '[7 5 #]', '[7 5 2]', '[7 5 3]', '[7 5 4]', '[7 5 n]', '[7 5]', '[7 6 2]', '[7 9 4]', '[7 n]', '[7 nr4 2]', '[7 nr5 2]', '[7 nr5]', '[7]', '[7_]', '[8 #6\\\\ 3]', '[8 #]', '[8 -]', '[8 2]', '[8 3 5]', '[8 3]', '[8 4]', '[8 5 #]', '[8 5 3]', '[8 5]', '[8 6 #]', '[8 6 -]', '[8 6 3]', '[8 6 4]', '[8 6]', '[8 n]', '[8 nr6]', '[8]', '[9 #5\\\\]', '[9 #5| 3]', '[9 #]', '[9 -]', '[9 3 5]', '[9 4]', '[9 5 3]', '[9 5 4]', '[9 6 4]', '[9 6]', '[9 7 #]', '[9 7 3]', '[9 7 4]', '[9 7]', '[9 nr4]', '[9 nr7]', '[9]', '[n]', '[n_]', '[nr4]', '[nr5 6]', '[nr5]', '[nr6 #4| 3]', '[nr6 4 2]', '[nr6 4 3]', '[nr6 5]', '[nr6]', '[nr7 #]', '[nr7 4 2]', '[nr7 5]', '[nr7]']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>[ ]</th>\n",
       "      <th>[# 7]</th>\n",
       "      <th>[#2\\]</th>\n",
       "      <th>[#2| 4]</th>\n",
       "      <th>[#2|]</th>\n",
       "      <th>[#4| 2]</th>\n",
       "      <th>[#4| 6]</th>\n",
       "      <th>[#4|]</th>\n",
       "      <th>[#5\\ #]</th>\n",
       "      <th>[#5\\ 4]</th>\n",
       "      <th>...</th>\n",
       "      <th>[nr5]</th>\n",
       "      <th>[nr6 #4| 3]</th>\n",
       "      <th>[nr6 4 2]</th>\n",
       "      <th>[nr6 4 3]</th>\n",
       "      <th>[nr6 5]</th>\n",
       "      <th>[nr6]</th>\n",
       "      <th>[nr7 #]</th>\n",
       "      <th>[nr7 4 2]</th>\n",
       "      <th>[nr7 5]</th>\n",
       "      <th>[nr7]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BWV_13.06_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_174.05_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_251_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_244.32_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BWV_248.42_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             [ ]  [# 7]  [#2\\]  [#2| 4]  [#2|]  [#4| 2]  [#4| 6]  [#4|]  \\\n",
       "BWV_13.06_   0.0    0.0    0.0      0.0    0.0      0.0      0.0    0.0   \n",
       "BWV_174.05_  0.0    0.0    0.0      0.0    0.0      0.0      0.0    0.0   \n",
       "BWV_251_     0.0    0.0    0.0      0.0    0.0      0.0      0.0    0.0   \n",
       "BWV_244.32_  0.0    0.0    0.0      0.0    0.0      0.0      0.0    0.0   \n",
       "BWV_248.42_  0.0    0.0    0.0      0.0    0.0      0.0      0.0    0.0   \n",
       "\n",
       "             [#5\\ #]  [#5\\ 4]  ...     [nr5]  [nr6 #4| 3]  [nr6 4 2]  \\\n",
       "BWV_13.06_       0.0      0.0  ...  0.000000          0.0        0.0   \n",
       "BWV_174.05_      0.0      0.0  ...  0.099416          0.0        0.0   \n",
       "BWV_251_         0.0      0.0  ...  0.000000          0.0        0.0   \n",
       "BWV_244.32_      0.0      0.0  ...  0.000000          0.0        0.0   \n",
       "BWV_248.42_      0.0      0.0  ...  0.000000          0.0        0.0   \n",
       "\n",
       "             [nr6 4 3]  [nr6 5]     [nr6]  [nr7 #]  [nr7 4 2]  [nr7 5]  [nr7]  \n",
       "BWV_13.06_         0.0      0.0  0.148579      0.0        0.0      0.0    0.0  \n",
       "BWV_174.05_        0.0      0.0  0.000000      0.0        0.0      0.0    0.0  \n",
       "BWV_251_           0.0      0.0  0.115714      0.0        0.0      0.0    0.0  \n",
       "BWV_244.32_        0.0      0.0  0.134735      0.0        0.0      0.0    0.0  \n",
       "BWV_248.42_        0.0      0.0  0.000000      0.0        0.0      0.0    0.0  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b[\\w\\\\\\ # - |]+\\b\")\n",
    "# vectorizer = TfidfVectorizer(token_pattern=r\"![^\\[\\]]+!\")\n",
    "vectorizer = TfidfVectorizer(token_pattern=r\"\\[[^\\[\\]]+\\]\")\n",
    "\n",
    "# vectorizer = TfidfVectorizer(token_pattern=r\"(?u)\\b.+\\b\")\n",
    "vectorized_data = vectorizer.fit_transform(df['fb'])\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "tfidf_df = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names(),index=df.index)\n",
    "\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e63f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed82c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848952f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-74fd6872b2cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                              \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                             min_df=10)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mvectorized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m countvec_df = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names(),\n\u001b[1;32m     11\u001b[0m                            index=df.index)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1132\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m   1135\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b[\\w\\\\\\ # - |]+\\b\", \n",
    "#                              ngram_range=(2,2),\n",
    "#                             min_df=3)\n",
    "# vectorizer = CountVectorizer(token_pattern=r\"![^!]+!\", \n",
    "vectorizer = CountVectorizer(token_pattern=r\"\\[[^\\[]]+\\]\",                              \n",
    "                             ngram_range=(2,2),\n",
    "                            min_df=10)\n",
    "vectorized_data = vectorizer.fit_transform(df['fb'])\n",
    "countvec_df = pd.DataFrame(vectorized_data.toarray(), columns=vectorizer.get_feature_names(),\n",
    "                           index=df.index)\n",
    "countvec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f2813",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[10,10])\n",
    "plt.imshow(countvec_df)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb444d5",
   "metadata": {},
   "source": [
    "# Find the most common n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=[5,10])\n",
    "temp = countvec_df.sum(axis=0).sort_values(ascending=False)[:20].reset_index()\n",
    "temp\n",
    "sns.barplot(data=temp,y='index',x=0)\n",
    "# sns.countplot(data=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ca50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b6482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
